# Terminology  
Collection of terms that I have found to be useful in the data science field.  

---

**Overfitting:** 
- Overfitting occurs when a machine learning algorithm extracts too much from the data noise, causing it to have a poor generalization error.  Essentially the algorithm is memorizing the training data instead of learning how to generalize knowledge from it.  
- Regularization is a process used to reduce the complexity of a machine learning algorithm, allowing it to capture the signal in the data without adjusting too much to the noise.  
  
**Feature Engineering:** one of the most important tasks for a data scientist. The right features are necessary for the machine learning algorithm to make good decisions. Unsupervised learning can be a way to automatically extract features.  

**Outliers:** If machine learning algorithms train on rare outliers, their generalization error will be lower than if they ignored or addressed outliers separately.  

**Data Drift:** If the data the model is making predictions on differs statistically from the data the model trained on, the model may need to be retrained to better represent the current data.  

**Cross Validation:** is a technique which involves reserving a particular sample of a dataset which is not used to train the model. Later, the model is tested on this sample to evaluate the performance. There are various methods of performing cross validation such as [1]: 
- Leave one out cross validation (LOOCV)
- k-fold cross validation
- Stratified k-fold cross validation
- Adversarial validation  

**Data mining**  is a study of extracting useful information from structured/unstructured data taken from various sources. This is done usually for
- Mining for frequent patterns
- Mining for associations
- Mining for correlations
- Mining for clusters
- Mining for predictive analysis 

**EDA:** exploratory data analysis is a phase used for data science pipeline in which the focus is to understand insights of the data through visualization or by statistical analysis.  

**Feature reduction:** the process of reducing the number of features to work on a computation intensive task without losing a lot of information.  
- PCA is one of the most popular feature reduction techniques, where we combine correlated variables to reduce the features.  

**Hidden Markov Process:** a Markov process in which the states are invisible or hidden, and the model developed to estimate these hidden states is known as the Hidden Markov Model (HMM). However, the output (data) dependent on the hidden states is visible. This output data generated by HMM gives some cue about the sequence of states.  
- HMM are widely used for pattern recognition in speech recognition, part-of-speech tagging, handwriting recognition, and reinforcement learning.  

**Hyperparameter:** a parameter whose value is set before training a machine learning or deep learning model. Different models require different hyperparameters and some require none. Hyperparameters should not be confused with the parameters of the model because the parameters are estimated or learned from the data.  
Some keys points about the hyperparameters are: 
- They are often used in processes to help estimate model parameters.
- They are often manually set.
- They are often tuned to tweak a modelâ€™s performance  
Number of trees in a Random Forest, eta in XGBoost, and k in k-nearest neighbours are some examples of hyperparameters.  
  
## Deep Learning Terms

**Dropout:** refers to dropping out or ignoring units during the training phase in a neural network.  
- Why is it necessary?  When a fully connected layer contains most of the parameters, the neurons may become co-dependent during the training phase which lessens the individual power of each neuron. As a result, the training data may be over-fit.
- TL;DR: Reduces chance of over-fitting.

Terms come from the following:  
- https://www.analyticsvidhya.com/glossary-of-common-statistics-and-machine-learning-terms/
- https://www.dataquest.io/blog/data-science-glossary/
- https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5

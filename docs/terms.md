# Terms  
Below is a collection of terms that I have found to be useful in the data science field.  

---

**Overfitting**  
- Overfitting occurs when a machine learning algorithm extracts too much from the data noise, causing it to have a poor generalization error.  Essentially the algorithm is memorizing the training data instead of learning how to generalize knowledge from it.  
- Regularization is a process used to reduce the complexity of a machine learning algorithm, allowing it to capture the signal in the data without adjusting too much to the noise.  
  
**Feature Engineering**  
- Feature Engineering is one of the most important tasks for a data scientist. The right features are necessary for the machine learning algorithm to make good decisions. Unsupervised learning can be a way to automatically extract features.  

**Outliers**  
- If machine learning algorithms train on rare outliers, their generalization error will be lower than if they ignored or addressed outliers separately.  

**Data Drift**  
- If the data the model is making predictions on differs statistically from the data the model trained on, the model may need to be retrained to better represent the current data.